Set up a network  |  Vertex AI Workbench  |  Google Cloud Documentation
Skip to main content
Technology areas
AI and ML
Application development
Application hosting
Compute
Data analytics and pipelines
Databases
Distributed, hybrid, and multicloud
Generative AI
Industry solutions
Networking
Observability and monitoring
Security
Storage
Cross-product tools
Access and resources management
Costs and usage management
Infrastructure as code
Migration
SDK, languages, frameworks, and tools
/
Console
English
Deutsch
Español – América Latina
Français
Português – Brasil
中文 – 简体
日本語
한국어
Sign in
Vertex AI Workbench
Start free
Guides
Reference
Samples
Support
Resources
Technology areas
More
Guides
Reference
Samples
Support
Resources
Cross-product tools
More
Console
Discover
Overview
Introduction to Vertex AI
MLOps on Vertex AI
Interfaces for Vertex AI
Vertex AI beginner's guides
Train an AutoML model
Train a custom model
Get inferences from a custom model
Train a model using Vertex AI and the Python SDK
Introduction
Prerequisites
Create a notebook
Create a dataset
Create a training script
Train a model
Make an inference
Integrated ML frameworks
PyTorch
TensorFlow
Vertex AI for BigQuery users
Glossary
Get started
Set up a project and a development environment
Install the Vertex AI SDK for Python
Choose a training method
Try a tutorial
Tutorials overview
AutoML tutorials
Hello image data
Overview
Set up your project and environment
Create a dataset and import images
Train an AutoML image classification model
Evaluate and analyze model performance
Deploy a model to an endpoint and make an inference
Clean up your project
Hello tabular data
Overview
Set up your project and environment
Create a dataset and train an AutoML classification model
Deploy a model and request an inference
Clean up your project
Custom training tutorials
Train a custom tabular model
Train a TensorFlow Keras image classification model
Overview
Set up your project and environment
Train a custom image classification model
Serve predictions from a custom image classification model
Clean up your project
Fine-tune an image classification model with custom data
Custom training notebook tutorials
Use Generative AI and LLMs
About Generative AI
Use Vertex AI development tools
Development tools overview
Use the Vertex AI SDK
Overview
Introduction to the Vertex AI SDK for Python
Vertex AI SDK for Python classes
Vertex AI SDK classes overview
Data classes
Training classes
Model classes
Prediction classes
Tracking classes
Use Vertex AI in notebooks
Choose a notebook solution
Colab Enterprise
Quickstart:Create a notebook by using the console
Connect to a runtime
Manage runtimes and runtime templates
Create a runtime template
Create a runtime
Vertex AI Workbench
Introduction
Notebook tutorials
Get started
Create an instance by using the Console
Schedule a notebook run
Set up an instance
Create an instance
Create a specific version of an instance
Create an instance with user credential access
Create an instance with Confidential Computing
Add a conda environment
Idle shutdown
Create an instance using a custom container
Create a Dataproc-enabled instance
Create an instance with third party credentials
Manage features through metadata
Use reservations
Connect to data
Query data in BigQuery from within JupyterLab
Access Cloud Storage buckets and files in JupyterLab
Explore and visualize data
Explore and visualize data in BigQuery
Maintain
Manage your conda environment
Back up and restore
Save a notebook to GitHub
Use a snapshot
Use Cloud Storage
Shut down an instance
Upgrade the environment of an instance
Access JupyterLab by using SSH
Migrate data to a new instance
Change machine type and configure GPUs
Provision resources using Terraform
Monitor
Monitor health status
Control access
Access control
Manage access to an instance
Manage access to an instance's JupyterLab interface
Use customer-managed encryption keys
Use an instance within a service perimeter
Troubleshoot Vertex AI Workbench
Vertex AI Workbench release notes
Managed notebooks
Introduction to managed notebooks
Get started
Create a managed notebooks instance by using the Cloud console
Schedule a managed notebooks run
Set up a managed notebooks instance
Create an instance with a custom container
Run a managed notebooks instance on a Dataproc cluster
Use Dataproc Serverless Spark with managed notebooks
Idle shutdown
Managed notebooks versions
Connect to data
Query data in BigQuery from within JupyterLab
Access Cloud Storage buckets and files in JupyterLab
Explore and visualize data
Overview
Explore and visualize data in BigQuery
Develop a model
Model development in a managed notebooks instance
Deploy
Run notebook files with the executor
Run notebook executions with parameters
Maintain
Migrate to a Vertex AI Workbench instance
Save a notebook to GitHub
Change machine type and configure GPUs of a managed notebooks instance
Upgrade the environment of a managed notebooks instance
Migrate data to a new managed notebooks instance
Monitor
Audit logging
Control access
Access control
Manage access to an instance
Manage access to an instance's JupyterLab interface
Use customer-managed encryption keys
Set up a network
Use a managed notebooks instance within a service perimeter
Troubleshoot managed notebooks
User-managed notebooks
Introduction to user-managed notebooks
Get started
Create a user-managed notebooks instance by using the Cloud console
Set up a user-managed notebooks instance
Create a specific version of an instance
Install dependencies
Choose a virtual machine image
Create an instance with a custom container
Explore data
Data science with R on Google Cloud: Exploratory data analysis tutorial
Monitor
Monitor health status
Audit logging
Control access
Access control
Manage access to an instance
Manage access to an instance's JupyterLab interface
Customer-managed encryption keys
Use a user-managed notebooks instance within a service perimeter
Use a shielded virtual machine with user-managed notebooks
Tutorial: Create a notebooks instance in a VPC network
Maintain
Migrate to a Vertex AI Workbench instance
Save a notebook to GitHub
Back up your data by using a snapshot
Shut down a user-managed notebooks instance
Change machine type and configure GPUs of a user-managed notebooks instance
Upgrade the environment of a user-managed notebooks instance
Migrate data to a new user-managed notebooks instance
Register a legacy instance with Notebooks API
Access JupyterLab by using SSH
Troubleshoot user-managed notebooks
Terraform support for Vertex AI
Managed Training on reserved clusters
Managed Training overview
Get started with Managed Training
Predictive AI model development
Overview
AutoML model development
AutoML training overview
Image data
Classification
Prepare data
Create dataset
Train model
Evaluate model
Get predictions
Interpret results
Object detection
Prepare data
Create dataset
Train model
Evaluate model
Get predictions
Interpret results
Encode image data using Base64
Export an AutoML Edge model
Tabular data
Overview
Introduction to tabular data
Tabular Workflows
Overview
Feature engineering
End-to-End AutoML
Overview
Train a model
Get online inferences
Get batch inferences
TabNet
Overview
Train a model
Get online inferences
Get batch inferences
Wide & Deep
Overview
Train a model
Get online inferences
Get batch inferences
Forecasting
Overview
Train a model
Get online inferences
Get batch inferences
Pricing
Service accounts
Manage quotas
Perform classification and regression with AutoML
Overview
Quickstart: AutoML Classification (Cloud Console)
Prepare training data
Create a dataset
Train a model
Evaluate model
View model architecture
Get online inferences
Get batch inferences
Export model
Perform forecasting with AutoML
Overview
Prepare training data
Create a dataset
Train a model
Evaluate model
Get inferences
Hierarchical forecasting
Perform forecasting with ARIMA+
Perform forecasting with Prophet
Perform entity reconciliation
Feature attributions for classification and regression
Feature attributions for forecasting
Data types and transformations for tabular AutoML data
Training parameters for forecasting
Data splits for tabular data
Best practices for creating tabular training data
Forecast with Timeseries Insights
Train an AutoML Edge model
Using the Console
Using the API
AutoML Text
Migrate from AutoML text to Gemini
Gemini for AutoML text users
Vertex AI Training
Overview of custom training in Vertex AI
Load and prepare data
Data preparation overview
Use Cloud Storage as a mounted file system
Mount an NFS share for custom training
Use managed datasets
Prepare training application
Understand the custom training service
Prepare training code
Use prebuilt containers
Create a Python training application for a prebuilt container
Prebuilt containers for custom training
Use custom containers
Custom containers for training
Create a custom container
Containerize and run training code locally
Use Deep Learning VM Images and Containers
Train on a persistent resource
Overview
Create persistent resource
Run training jobs on a persistent resource
Get persistent resource information
Reboot a persistent resource
Delete a persistent resource
Configure training job
Choose a custom training method
Configure container settings for training
Configure compute resources for training
Use reservations with training
Use Spot VMs with training
Submit training job
Create custom jobs
Hyperparameter tuning
Hyperparameter tuning overview
Use hyperparameter tuning
Create training pipelines
Schedule jobs based on resource availability
Use distributed training
Training with Cloud TPU VMs
Use private IP for custom training
Use Private Service Connect interface for training (recommended)
Perform Neural Architecture Search
Overview
Set up environment
Beginner tutorials
Best practices and workflow
Proxy task design
Optimize training speed for PyTorch
Use prebuilt training containers and search spaces
Monitor and debug
Monitor and debug training using an interactive shell
Profile model training performance
Optimize using Vertex AI Vizier
Overview of Vertex AI Vizier
Create Vertex AI Vizier studies
Vertex AI Vizier notebook tutorials
Get inferences
Tutorial: Build a pipeline for continuous training
Create custom organization policy constraints
Ray on Vertex AI
Ray on Vertex AI overview
Set up for Ray on Vertex AI
Create a Ray cluster on Vertex AI
Monitor Ray clusters on Vertex AI
Scale a Ray cluster on Vertex AI
Develop a Ray application on Vertex AI
Run Spark on Ray cluster on Vertex AI
Use Ray on Vertex AI with BigQuery
Deploy a model and get inferences
Delete a Ray cluster
Ray on Vertex AI notebook tutorials
Generative AI model development
Overview
Create and manage datasets
Overview
Data splits for AutoML models
Create an annotation set
Delete an annotation set
Add labels (console)
Export metadata and annotations from a dataset
Manage dataset versions
Use Data Catalog to search for model and dataset resources
Get inferences
Overview
Configure models for inference
Export model artifacts for inference
Prebuilt containers for inference
Custom container requirements for inference
Use a custom container for inference
Use arbitrary custom routes
Use the optimized TensorFlow runtime
Serve inferences with NVIDIA Triton
Custom inference routines
Get online inferences
Create an endpoint
Choose an endpoint type
Create a public endpoint
Use dedicated public endpoints (recommended)
Use dedicated private endpoints based on Private Service Connect (recommended)
Use private services access endpoints
Deploy a model to an endpoint
Overview of model deployment
Compute resources for inference
Deploy a model by using the Google Cloud console
Deploy a model by using the gcloud CLI or Vertex AI API
Use autoscaling for inference
Use a rolling deployment to replace a deployed model
Undeploy a model and delete the endpoint
Use Cloud TPUs for online inference
Use reservations with online inference
Use Flex-start VMs with inference
Use Spot VMs with inference
Get an online inference
View online inference metrics
View endpoint metrics
View DCGM metrics
Share resources across deployments
Use online inference logging
Get batch inferences
Get batch inferences from a custom model
Use reservations with batch inference
Get batch prediction from a self-deployed Model Garden model
Serve generative AI models
Deploy generative AI models
Serve Gemma open models using Cloud TPUs with Saxml
Serve Llama 3 open models using multi-host Cloud TPUs with Saxml
Serve a DeepSeek-V3 model using multi-host GPU deployment
Custom organization policies
Vertex AI inference notebook tutorials
Perform vector similarity searches
Vector Search overview
Try it
Get started
Vector Search quickstart
Before you begin
Notebook tutorials
About hybrid search
Create and manage index
Input data format and structure
Create and manage your index
Storage-optimized indexes
Index configuration parameters
Update and rebuild index
Filter vector matches
Import index data from BigQuery
Embeddings with metadata
Deploy and query an index
Private Service Connect (recommended)
Set up Vector Search with Private Service Connect
Query
JSON Web Token authentication
Public endpoint
Deploy
Query
Private services access
Set up a VPC network peering connection
Deploy
Query
JSON Web Token authentication
Monitor a deployed index
Use custom organization policies
Get support
Machine learning operations (MLOps)
Manage features
Feature management in Vertex AI
Vertex AI Feature Store
About Vertex AI Feature Store
Set up features
Prepare data source
Create a feature group
Create a feature
Set up online serving
Online serving types
Create an online store instance
Create a feature view instance
Control access
Control access to resources
Sync online store
Start a data sync
List sync operations
Update features in a feature view
Serve features
Serve features from online store
Serve historical feature values
Monitor
Monitor features
Manage feature resources
List feature groups
List features
Update a feature group
Update a feature
Delete a feature group
Delete a feature
Manage online store resources
List online stores
List feature views
Update an online store
Update a feature view
Delete an online store
Delete a feature view
Feature metadata
Update labels
Search for resources
Search for resources
Search for resource metadata in Data Catalog
Manage embeddings
Search using embeddings
Notebook tutorials
Vertex AI Feature Store tutorial notebooks
Vertex AI Feature Store (Legacy)
About Vertex AI Feature Store (Legacy)
Data model and resources
Source data requirements
Setup
Best practices
Use Vertex AI Feature Store (Legacy)
Manage featurestores
Manage entity types
Manage and find features
Batch import
Streaming import
Online serving
Fetch training data
Export feature values
Delete feature values
Monitoring
Control access to resources
Manage models
Introduction to Vertex AI Model Registry
Versioning in Model Registry
Import models to Model Registry
Copy models in Model Registry
Delete a model
Integrate with BigQuery ML
Use model aliases
Use model labels
Use Data Catalog to search for model and dataset resources
Evaluate models
Model evaluation in Vertex AI
Perform model evaluation in Vertex AI
Model evaluation for fairness
Introduction to model evaluation for fairness
Data bias metrics for Vertex AI
Model bias metrics for Vertex AI
Model evaluation notebook tutorials
Orchestrate ML workflows using pipelines
Introduction
Interfaces
Configure your project
Build a pipeline
Run a pipeline
Use pipeline templates
Create, upload, and use a pipeline template
Use a prebuilt template from the Template Gallery
Configure your pipeline
Configure execution caching
Configure failure policy
Configure retries for a pipeline task
Specify machine types for a pipeline step
Request Google Cloud machine resources with Vertex AI Pipelines
Configure Private Service Connect interface (recommended)
Configure secrets with Secret Manager
Configure a pipeline run on a persistent resource
Schedule and trigger pipeline runs
Schedule a pipeline run with scheduler API
Trigger a pipeline run with Pub/Sub
Cancel or delete pipeline runs
Cancel pipeline runs
Delete pipeline runs
Rerun a pipeline
Monitor pipeline execution
View pipeline metrics
View pipeline job logs
Route logs to a Cloud Pub/Sub sink
Configure email notifications
Visualize results
Visualize and analyze pipeline results
Track the lineage of pipeline artifacts
Output HTML and Markdown
Resource labeling by Vertex AI Pipelines
Understand pipeline run costs
Migrate from Kubeflow Pipelines to Vertex AI Pipelines
Use custom constraints
Google Cloud Pipeline Components
Quickstart
Introduction to Google Cloud Pipeline Components
Google Cloud Pipeline Component list
Use Google Cloud Pipeline Components
Build your own pipeline components
Vertex AI Pipelines tutorials
Tutorial notebooks
Track and analyze your ML metadata
Introduction to Vertex ML Metadata
Data model and resources
Configure your project's metadata store
Use Vertex ML Metadata
Track Vertex ML Metadata
Analyze Vertex ML Metadata
Manage Vertex ML Metadata
System schemas
Create and use custom schemas
Use custom constraints with metadata stores
Vertex ML Metadata notebook tutorials
Understand model behavior
Introduction to Explainable AI
Configure example-based explanations for custom training
Configure feature-based explanations for custom training
Configure explanations
Configure visualization settings
Improve explanations
Configure feature-based explanations for AutoML image classification
Configure visualization settings
Improve explanations
Use TensorFlow for explanations
Get explanations
Limitations of Explainable AI
Explainable AI notebook tutorials
Monitor model quality
Introduction to Model Monitoring
Model Monitoring v2
Set up model monitoring
Run monitoring jobs
Manage model monitors
Model Monitoring v1
Provide schemas to Model Monitoring
Monitor feature skew and drift
Monitor feature attribution skew and drift
Model Monitoring for batch predictions
Track Experiments
Introduction to Vertex AI Experiments
Set up for Vertex AI Experiments
Create an experiment
Create and manage experiment runs
Log data
Autolog data to an experiment run
Manually log data to an experiment run
Log models to an experiment run
Track executions and artifacts
Add pipeline run to experiment
Run training job with experiment tracking
Compare and analyze runs
Use Vertex AI TensorBoard
Introduction to Vertex AI TensorBoard
Set up Vertex AI TensorBoard
Configure training script
Use Vertex AI TensorBoard with custom training
Use Vertex AI TensorBoard with Vertex AI Pipelines
Manually log TensorBoard data
Upload existing logs
View Vertex AI TensorBoard
Notebook tutorials
Get started with Vertex AI Experiments
Compare pipeline runs
Model training
Compare models
Autologging
Custom training autologging
Track parameters and metrics for custom training
Delete outdated Vertex AI TensorBoard experiments
Vertex AI TensorBoard custom training with custom container
Vertex AI TensorBoard custom training with prebuilt container
Vertex AI TensorBoard hyperparameter tuning with HParams dashboard
Profile model training performance using Cloud Profiler
Profile model training performance using Cloud Profiler in custom training with prebuilt container
Vertex AI TensorBoard integration with Vertex AI Pipelines
Administer
Access control
Access control with IAM
IAM permissions
Set up a project for a team
Control access to Vertex AI endpoints
Use a custom service account
Use customer-managed encryption keys
Access Transparency
Monitor Vertex AI resources
Cloud Monitoring metrics
Audit logging information
Networking
Networking access overview
Accessing the Vertex AI API
Accessing Vertex AI services through private services access
Accessing Vertex AI services through PSC endpoints
Accessing Vertex AI services through PSC interfaces
Set up VPC Network Peering
Set up connectivity to other networks
Set up a Private Service Connect interface
Tutorial: Access training pipelines privately from on-premises
Tutorial: Access a Vector Search index privately from on-premises
Tutorial: Access the Generative AI API from on-premises
Tutorial: Access batch predictions privately from on-premises
Tutorial: Create a Vertex AI Workbench instance in a VPC network
Security
VPC Service Controls
Allow public endpoint access to protected resources from outside a perimeter
Allow multicloud access to protected resources from outside a perimeter
Allow access to protected resources from inside a perimeter
Name resources
Samples and tutorials
Notebook tutorials
Code samples
All Vertex AI code samples
Code samples for all products
AI and ML
Application development
Application hosting
Compute
Data analytics and pipelines
Databases
Distributed, hybrid, and multicloud
Generative AI
Industry solutions
Networking
Observability and monitoring
Security
Storage
Access and resources management
Costs and usage management
Infrastructure as code
Migration
SDK, languages, frameworks, and tools
Home
Documentation
AI and ML
Vertex AI Workbench
Guides
Send feedback
Stay organized with collections
Save and categorize content based on your preferences.
Set up a network
Vertex AI Workbench managed notebooks is
deprecated
. On
    April 14, 2025, support for
    managed notebooks ended and the ability to create managed notebooks instances
    was removed. Existing instances will continue to function until
    March 30, 2026, but patches, updates, and upgrades
    won't be available. To continue using Vertex AI Workbench, we recommend that you
migrate
    your managed notebooks instances to Vertex AI Workbench instances
.
This page describes networking options for Vertex AI Workbench
managed notebooks instances and shows you how to
set up a network.
This guide is recommended for networking administrators
who are already familiar with Google Cloud networking concepts.
Overview
This guide describes how to configure each of the following network options:
Google-managed network
VPC network in the same project as your managed notebooks instance
Shared VPC network
By default, your managed notebooks instance uses
a Google-managed network. If you want to,
you can instead specify a Virtual Private Cloud network located within your
project or a Shared VPC network that you have access to.
If you specify a VPC or Shared VPC network,
the network requires a
private services
access
connection.
Supported feature comparison
The following table describes which common features are supported for each
networking option.
Feature
Google-managed network
VPC network in your instance's project
Shared VPC network
External IP
Supported
Supported
Supported
Internal IP
Supported
Supported
Supported
Private Google Access
Not supported
Supported
Supported
VPC
Supported
Supported
Supported
VPC Network Peering (requires Service Networking)
Not supported
Supported
Supported
Note:
Because VPC Network Peering is not supported when using
the default Google-managed network, an external IP address is required
in order to download additional resources such as Python or Conda packages.
Use the default Google-managed network
The default network is Google-managed and requires no additional setup
to configure.
When you create a managed notebooks instance
with the default Google-managed network,
the instance is deployed in a
tenant project
and uses a default VPC and subnet.
To download additional resources such as Python or Conda packages,
a managed notebooks instance using the
default Google-managed network requires an external IP address.
Connect your instance to a VPC network in the same project
To connect a managed notebooks instance
to a VPC network in the same project
as your managed notebooks instance,
complete the following steps.
This option requires you to configure
private services access
.
Before you begin
Select or
create a Google Cloud
project
where your
managed notebooks instance will be.
Go to project selector
Verify that billing is enabled for your Google Cloud project
.
Enable the Compute Engine, Notebooks, and Service Networking APIs.
Roles required to enable APIs
To enable APIs, you need the Service Usage Admin IAM
          role (
roles/serviceusage.serviceUsageAdmin
), which
          contains the
serviceusage.services.enable
permission.
Learn how to grant
          roles
.
Enable the APIs
Install the
gcloud CLI
to run the
gcloud
command-line examples in this guide.
Set up private services access for your VPC
When you set up private services access,
you establish a private connection between your network
and a network owned by Google or a third party service (
service producers
).
In this case, your managed notebooks instance
is a service producer. To
set up
private services access
, you
reserve an IP range
for the service producer, and then
create
a peering connection
with your managed notebooks instance.
Configure your project ID
To configure your project ID, use the following command.
gcloud
config
set
project
PROJECT_ID
Replace
PROJECT_ID
with the
project ID
of the Google Cloud project where
your managed notebooks instance will be.
You'll create the instance later.
Enable the APIs
Make sure you have
enabled the required APIs
.
Create or select a VPC
Create or select an existing VPC in a
supported
managed notebooks region
to use with your managed notebooks instance.
If you already have a VPC
with private services access configured,
and you want to use that VPC to peer with
your managed notebooks instance,
skip to
Create a managed notebooks instance
.
If you need to create a new VPC,
run the following gcloud CLI commands:
gcloud
compute
networks
create
VPC_NAME
\
--project
=
PROJECT_ID
--subnet-mode
=
auto
\
--mtu
=
1460
--bgp-routing-mode
=
regional

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-icmp
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
ICMP
\
connections
\
from
\
any
\
source
\
to
\
any
\
instance
\
on
\
the
\
network.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
0
.0.0.0/0
\
--action
=
ALLOW
--rules
=
icmp

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-internal
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
connections
\
from
\
any
\
source
\
in
\
the
\
network
\
IP
\
range
\
to
\
any
\
instance
\
on
\
the
\
network
\
using
\
all
\
protocols.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
10
.128.0.0/9
\
--action
=
ALLOW
--rules
=
all

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-rdp
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
RDP
\
connections
\
from
\
any
\
source
\
to
\
any
\
instance
\
on
\
the
\
network
\
using
\
port
\
3389
.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
0
.0.0.0/0
\
--action
=
ALLOW
--rules
=
tcp:3389

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-ssh
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
TCP
\
connections
\
from
\
any
\
source
\
to
\
any
\
instance
\
on
\
the
\
network
\
using
\
port
\
22
.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
0
.0.0.0/0
\
--action
=
ALLOW
--rules
=
tcp:22
Replace
VPC_NAME
with a name for
your VPC.
Create and configure DNS entries
Vertex AI Workbench managed notebooks instances use several domains that a
  Virtual Private Cloud network doesn't handle by default.
  To ensure that your VPC network correctly handles requests sent
  to those domains, use Cloud DNS to add DNS records. For more
  information about VPC routes, see
Routes
.
To create a
managed zone
for
  a domain, add a DNS entry that will route the request, and execute
  the transaction, complete the following steps.
  Repeat these steps for each of
several
  domains
that you need to handle requests for, starting
  with
*.notebooks.googleapis.com
.
In
Cloud Shell
or any environment where the
Google Cloud CLI
is installed, enter the following
Google Cloud CLI
commands.
To create a private managed zone
      for one of the domains that your
      VPC network needs to handle:
gcloud
dns
managed-zones
create
ZONE_NAME
\
--visibility
=
private
\
--networks
=
https://www.googleapis.com/compute/v1/projects/
PROJECT_ID
/global/networks/
NETWORK_NAME
\
--dns-name
=
DNS_NAME
\
--description
=
"Description of your managed zone"
Replace the following:
ZONE_NAME
: a name for the zone to create.
        You must use a separate zone for each domain. This zone name is used in
        each of the following steps.
PROJECT_ID
: the ID of the project that hosts your
        VPC network
NETWORK_NAME
: the name of the VPC
        network that you created earlier
DNS_NAME
: the part of the domain name that comes
        after the
*.
, with a period on the end.
        For example,
*.notebooks.googleapis.com
has a
DNS_NAME
of
notebooks.googleapis.com.
Start a transaction.
gcloud
dns
record-sets
transaction
start
--zone
=
ZONE_NAME
Add the following DNS A record. This reroutes traffic to
      Google's restricted IP addresses.
gcloud
dns
record-sets
transaction
add
\
--name
=
DNS_NAME
.
\
--type
=
A
199
.36.153.4
199
.36.153.5
199
.36.153.6
199
.36.153.7
\
--zone
=
ZONE_NAME
\
--ttl
=
300
Add the following DNS CNAME record to point to the A record
      that you just added. This redirects all traffic matching the
      domain to the IP addresses listed in the previous step.
gcloud
dns
record-sets
transaction
add
\
--name
=
\*
.
DNS_NAME
.
\
--type
=
CNAME
DNS_NAME
.
\
--zone
=
ZONE_NAME
\
--ttl
=
300
Execute the transaction.
gcloud
dns
record-sets
transaction
execute
--zone
=
ZONE_NAME
Repeat these steps for each of the following domains. For each
      repetition, change
ZONE_NAME
and
DNS_NAME
to the appropriate values for that
      domain. Keep
PROJECT_ID
and
NETWORK_NAME
the same each time. You already
      completed these steps for
*.notebooks.googleapis.com
.
*.notebooks.googleapis.com
*.notebooks.cloud.google.com
*.notebooks.googleusercontent.com
*.googleapis.com
to run code that interacts with other Google APIs
        and services
Reserve IP ranges for your managed notebooks instance
When you reserve an IP range for service producers, the range can be used by
your managed notebooks instance and other services. If you
plan to connect with other service producers using the same range,
you might want to allocate a larger range to accommodate them,
to avoid IP exhaustion.
Use the following command to set a reserved range using
gcloud compute addresses create
.
gcloud
compute
addresses
create
PEERING_RANGE_NAME
\
--global
\
--prefix-length
=
16
\
--description
=
"Managed notebooks range"
\
--network
=
NETWORK_NAME
\
--purpose
=
VPC_PEERING
Replace the following:
PEERING_RANGE_NAME
: the name of your range
NETWORK_NAME
: the name of your network
A
prefix-length
value of
16
means that a CIDR block
with a subnet mask of
/16
will be
reserved for use by Google Cloud services
such as Vertex AI Workbench managed notebooks.
To avoid an invalid service networking configuration, use a subnet mask of
/24
or lower.
Use the following command to verify the addresses.
gcloud
compute
addresses
list
Establish a peering connection
Establish a peering connection between your
VPC host project and Google's Service Networking, using
gcloud services vpc-peerings connect
.
gcloud
services
vpc-peerings
connect
\
--service
=
servicenetworking.googleapis.com
\
--network
=
NETWORK_NAME
\
--ranges
=
PEERING_RANGE_NAME
\
--project
=
PROJECT_ID
Note:
The
--ranges
flag accepts a list of ranges so that you can
specify multiple ranges if necessary.
To list the
peerings, use the following command.
gcloud
services
vpc-peerings
list
--network
=
NETWORK_NAME
Create a managed notebooks instance
Before using any of the request data,
  make the following replacements:
USER_ACCOUNT
: The user account in the form of an email address.
MACHINE_TYPE
: The
machine type
,
    for example
n1-standard-1
.
PROJECT_ID
: The project ID of your managed notebooks instance.
NETWORK_NAME
: The VPC network name.
LOCATION
: The region of your VPC network.
NOTEBOOK_NAME
: The name of your managed notebooks instance.
SUBNET_NAME
: The subnet name for your VPC network.
PEERING_RANGE_NAME
: Optional. The name of the peering range
    if you want to specify one.
HTTP method and URL:
POST https://notebooks.googleapis.com/v1/projects/
PROJECT_ID
/locations/
LOCATION
/runtimes?runtimeId=
NOTEBOOK_NAME
Request JSON body:
{
  "access_config": {
    "access_type": "SINGLE_USER",
    "runtime_owner": "
USER_ACCOUNT
"
  },
  "virtual_machine": {
    "virtual_machine_config": {
      "machine_type": "
MACHINE_TYPE
",
      "network": "projects/
PROJECT_ID
/global/networks/
NETWORK_NAME
",
      "subnet":  "projects/
PROJECT_ID
/regions/
LOCATION
/subnetworks/
SUBNET_NAME
",
      "internal_ip_only": true,
      "reserved_ip_range": "
PEERING_RANGE_NAME
" # Optional
    }
  }
}
To send your request, choose one of these options:
curl
Note:
The following command assumes that you have logged in to
          the
gcloud
CLI with your user account by running
gcloud init
or
gcloud auth login
, or by using
Cloud Shell
,
            which automatically logs you into the
gcloud
CLI
            .
          You can check the currently active account by running
gcloud auth list
.
Save the request body in a file named
request.json
,
      and execute the following command:
curl -X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json; charset=utf-8" \
-d @request.json \
"https://notebooks.googleapis.com/v1/projects/
PROJECT_ID
/locations/
LOCATION
/runtimes?runtimeId=
NOTEBOOK_NAME
"
PowerShell
Note:
The following command assumes that you have logged in to
          the
gcloud
CLI with your user account by running
gcloud init
or
gcloud auth login
.
          You can check the currently active account by running
gcloud auth list
.
Save the request body in a file named
request.json
,
      and execute the following command:
$cred = gcloud auth print-access-token
$headers = @{ "Authorization" = "Bearer $cred" }
Invoke-WebRequest `
-Method POST `
-Headers $headers `
-ContentType: "application/json; charset=utf-8" `
-InFile request.json `
-Uri "https://notebooks.googleapis.com/v1/projects/
PROJECT_ID
/locations/
LOCATION
/runtimes?runtimeId=
NOTEBOOK_NAME
" | Select-Object -Expand Content
Verify connectivity
To verify that your managed notebooks instance is connected
to the VPC
 network,
complete these steps.
In the Google Cloud console,
go to the
VPC network peering
page.
Go to VPC network peering
On the
VPC network peering
page, find your connection.
Export custom routes
If you use custom routes, you need to export them so that
Vertex AI Workbench managed notebooks can import them.
To export custom routes, you
update
the peering connection
in your VPC. Exporting custom routes sends all
eligible
static and dynamic routes
that are
in your VPC network, such as routes to your on-premises network,
to service producers' networks (in this case, managed notebooks).
This establishes the necessary connections and lets
managed notebooks instances send traffic back
to your on-premises network.
To list the name of the peering connection to update,
use the following command.
If you have multiple peering connections, omit the
--format
flag.
gcloud
services
vpc-peerings
list
\
--network
=
NETWORK_NAME
\
--service
=
servicenetworking.googleapis.com
\
--project
=
PROJECT_ID
\
--format
"value(peering)"
To update the peering connection to export custom routes,
use the following command.
gcloud
compute
networks
peerings
update
PEERING_NAME
\
--network
=
NETWORK_NAME
\
--export-custom-routes
\
--project
=
PROJECT_ID
Replace
PEERING_NAME
with the name of your peering connection.
Check the state of your peering connections
To check whether your peering connections are active,
you can list them using the following command.
gcloud
compute
networks
peerings
list
--network
NETWORK_NAME
Verify that the state of the peering connection that
you just created is
ACTIVE
.
Learn more about
active
peering connections
.
Connect your instance to a Shared VPC network
To connect a managed notebooks instance
to a Shared VPC network that you have access to,
complete the following steps.
This option requires you to configure
private services access
.
Before you begin
Select or
create a Google Cloud
project
where your
managed notebooks instance will be.
Go to project selector
Verify that billing is enabled for your Google Cloud project
.
Enable the Compute Engine, Notebooks, and Service Networking APIs.
Roles required to enable APIs
To enable APIs, you need the Service Usage Admin IAM
          role (
roles/serviceusage.serviceUsageAdmin
), which
          contains the
serviceusage.services.enable
permission.
Learn how to grant
          roles
.
Enable the APIs
When you use
Shared VPC
, you run
your managed notebooks instance in
a separate Google Cloud project than
your VPC host project.
Repeat the previous steps to enable the Compute Engine, Notebooks,
and Service Networking APIs
in your VPC host project.
Learn more about how to
provision Shared VPC
.
Install the
gcloud CLI
to run the
gcloud
command-line examples in this guide.
Set up private services access for your VPC
When you set up private services access,
you establish a private connection between your network
and a network owned by Google or a third party service (
service producers
).
In this case, your managed notebooks instance
is a service producer. To
set up
private services access
, you
reserve an IP range
for the service producer, and then
create
a peering connection
with your managed notebooks instance.
Configure your project ID
To configure your project ID, use the following command.
gcloud
config
set
project
PROJECT_ID
Replace
PROJECT_ID
with the
project ID
of your VPC host project. If you haven't created
the VPC yet, use the project ID where it will be after
it is created.
Enable the APIs
Make sure you have
enabled the required APIs
in both your VPC host project and
the Google Cloud project where
your managed notebooks instance will be.
Create or select a VPC
Create or select an existing VPC in a
supported
managed notebooks region
to use with your managed notebooks instance.
If you already have a VPC
with private services access configured,
and you want to use that VPC to peer with
your managed notebooks instance,
skip to
Create a managed notebooks instance
.
If you need to create a new VPC,
run the following gcloud CLI commands:
gcloud
compute
networks
create
VPC_NAME
\
--project
=
PROJECT_ID
--subnet-mode
=
auto
\
--mtu
=
1460
--bgp-routing-mode
=
regional

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-icmp
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
ICMP
\
connections
\
from
\
any
\
source
\
to
\
any
\
instance
\
on
\
the
\
network.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
0
.0.0.0/0
\
--action
=
ALLOW
--rules
=
icmp

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-internal
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
connections
\
from
\
any
\
source
\
in
\
the
\
network
\
IP
\
range
\
to
\
any
\
instance
\
on
\
the
\
network
\
using
\
all
\
protocols.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
10
.128.0.0/9
\
--action
=
ALLOW
--rules
=
all

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-rdp
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
RDP
\
connections
\
from
\
any
\
source
\
to
\
any
\
instance
\
on
\
the
\
network
\
using
\
port
\
3389
.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
0
.0.0.0/0
\
--action
=
ALLOW
--rules
=
tcp:3389

gcloud
compute
firewall-rules
create
VPC_NAME
-allow-ssh
\
--project
=
PROJECT_ID
\
--network
=
projects/
PROJECT_ID
/global/networks/
VPC_NAME
\
--description
=
Allows
\
TCP
\
connections
\
from
\
any
\
source
\
to
\
any
\
instance
\
on
\
the
\
network
\
using
\
port
\
22
.
\
--direction
=
INGRESS
--priority
=
65534
--source-ranges
=
0
.0.0.0/0
\
--action
=
ALLOW
--rules
=
tcp:22
Replace
VPC_NAME
with a name for
your VPC.
Create and configure DNS entries
Vertex AI Workbench managed notebooks instances use several domains that a
  Virtual Private Cloud network doesn't handle by default.
  To ensure that your VPC network correctly handles requests sent
  to those domains, use Cloud DNS to add DNS records. For more
  information about VPC routes, see
Routes
.
To create a
managed zone
for
  a domain, add a DNS entry that will route the request, and execute
  the transaction, complete the following steps.
  Repeat these steps for each of
several
  domains
that you need to handle requests for, starting
  with
*.notebooks.googleapis.com
.
In
Cloud Shell
or any environment where the
Google Cloud CLI
is installed, enter the following
Google Cloud CLI
commands.
To create a private managed zone
      for one of the domains that your
      VPC network needs to handle:
gcloud
dns
managed-zones
create
ZONE_NAME
\
--visibility
=
private
\
--networks
=
https://www.googleapis.com/compute/v1/projects/
PROJECT_ID
/global/networks/
NETWORK_NAME
\
--dns-name
=
DNS_NAME
\
--description
=
"Description of your managed zone"
Replace the following:
ZONE_NAME
: a name for the zone to create.
        You must use a separate zone for each domain. This zone name is used in
        each of the following steps.
PROJECT_ID
: the ID of the project that hosts your
        VPC network
NETWORK_NAME
: the name of the VPC
        network that you created earlier
DNS_NAME
: the part of the domain name that comes
        after the
*.
, with a period on the end.
        For example,
*.notebooks.googleapis.com
has a
DNS_NAME
of
notebooks.googleapis.com.
Start a transaction.
gcloud
dns
record-sets
transaction
start
--zone
=
ZONE_NAME
Add the following DNS A record. This reroutes traffic to
      Google's restricted IP addresses.
gcloud
dns
record-sets
transaction
add
\
--name
=
DNS_NAME
.
\
--type
=
A
199
.36.153.4
199
.36.153.5
199
.36.153.6
199
.36.153.7
\
--zone
=
ZONE_NAME
\
--ttl
=
300
Add the following DNS CNAME record to point to the A record
      that you just added. This redirects all traffic matching the
      domain to the IP addresses listed in the previous step.
gcloud
dns
record-sets
transaction
add
\
--name
=
\*
.
DNS_NAME
.
\
--type
=
CNAME
DNS_NAME
.
\
--zone
=
ZONE_NAME
\
--ttl
=
300
Execute the transaction.
gcloud
dns
record-sets
transaction
execute
--zone
=
ZONE_NAME
Repeat these steps for each of the following domains. For each
      repetition, change
ZONE_NAME
and
DNS_NAME
to the appropriate values for that
      domain. Keep
PROJECT_ID
and
NETWORK_NAME
the same each time. You already
      completed these steps for
*.notebooks.googleapis.com
.
*.notebooks.googleapis.com
*.notebooks.cloud.google.com
*.notebooks.googleusercontent.com
*.googleapis.com
to run code that interacts with other Google APIs
        and services
Reserve IP ranges for your managed notebooks instance
When you reserve an IP range for service producers, the range can be used by
your managed notebooks instance and other services. If you
plan to connect with other service producers using the same range,
you might want to allocate a larger range to accommodate them,
to avoid IP exhaustion.
Use the following command to set a reserved range using
gcloud compute addresses create
.
gcloud
compute
addresses
create
PEERING_RANGE_NAME
\
--global
\
--prefix-length
=
16
\
--description
=
"Managed notebooks range"
\
--network
=
NETWORK_NAME
\
--purpose
=
VPC_PEERING
Replace the following:
PEERING_RANGE_NAME
: the name of your range
NETWORK_NAME
: the name of your network
A
prefix-length
value of
16
means that a CIDR block
with a subnet mask of
/16
will be
reserved for use by Google Cloud services
such as Vertex AI Workbench managed notebooks.
To avoid an invalid service networking configuration, use a subnet mask of
/24
or lower.
Use the following command to verify the addresses.
gcloud
compute
addresses
list
Establish a peering connection
Establish a peering connection between your
VPC host project and Google's Service Networking, using
gcloud services vpc-peerings connect
.
gcloud
services
vpc-peerings
connect
\
--service
=
servicenetworking.googleapis.com
\
--network
=
NETWORK_NAME
\
--ranges
=
PEERING_RANGE_NAME
\
--project
=
PROJECT_ID
Note:
The
--ranges
flag accepts a list of ranges so that you can
specify multiple ranges if necessary.
To list the
peerings, use the following command.
gcloud
services
vpc-peerings
list
--network
=
NETWORK_NAME
Create a managed notebooks instance
Before using any of the request data,
  make the following replacements:
USER_ACCOUNT
: The user account in the form of an email address.
MACHINE_TYPE
: The
machine type
,
    for example
n1-standard-1
.
PROJECT_ID
: The project ID of your managed notebooks instance.
NETWORK_NAME
: The VPC network name.
LOCATION
: The region of your VPC network.
NOTEBOOK_NAME
: The name of your managed notebooks instance.
SUBNET_NAME
: The subnet name for your VPC network.
PEERING_RANGE_NAME
: Optional. The name of the peering range
    if you want to specify one.
HTTP method and URL:
POST https://notebooks.googleapis.com/v1/projects/
PROJECT_ID
/locations/
LOCATION
/runtimes?runtimeId=
NOTEBOOK_NAME
Request JSON body:
{
  "access_config": {
    "access_type": "SINGLE_USER",
    "runtime_owner": "
USER_ACCOUNT
"
  },
  "virtual_machine": {
    "virtual_machine_config": {
      "machine_type": "
MACHINE_TYPE
",
      "network": "projects/
PROJECT_ID
/global/networks/
NETWORK_NAME
",
      "subnet":  "projects/
PROJECT_ID
/regions/
LOCATION
/subnetworks/
SUBNET_NAME
",
      "internal_ip_only": true,
      "reserved_ip_range": "
PEERING_RANGE_NAME
" # Optional
    }
  }
}
To send your request, choose one of these options:
curl
Note:
The following command assumes that you have logged in to
          the
gcloud
CLI with your user account by running
gcloud init
or
gcloud auth login
, or by using
Cloud Shell
,
            which automatically logs you into the
gcloud
CLI
            .
          You can check the currently active account by running
gcloud auth list
.
Save the request body in a file named
request.json
,
      and execute the following command:
curl -X POST \
-H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json; charset=utf-8" \
-d @request.json \
"https://notebooks.googleapis.com/v1/projects/
PROJECT_ID
/locations/
LOCATION
/runtimes?runtimeId=
NOTEBOOK_NAME
"
PowerShell
Note:
The following command assumes that you have logged in to
          the
gcloud
CLI with your user account by running
gcloud init
or
gcloud auth login
.
          You can check the currently active account by running
gcloud auth list
.
Save the request body in a file named
request.json
,
      and execute the following command:
$cred = gcloud auth print-access-token
$headers = @{ "Authorization" = "Bearer $cred" }
Invoke-WebRequest `
-Method POST `
-Headers $headers `
-ContentType: "application/json; charset=utf-8" `
-InFile request.json `
-Uri "https://notebooks.googleapis.com/v1/projects/
PROJECT_ID
/locations/
LOCATION
/runtimes?runtimeId=
NOTEBOOK_NAME
" | Select-Object -Expand Content
Verify connectivity
To verify that your managed notebooks instance is connected
to the Shared VPC network,
complete these steps.
In the Google Cloud console,
go to the
VPC network peering
page.
Go to VPC network peering
On the
VPC network peering
page, find your connection.
Export custom routes
If you use custom routes, you need to export them so that
Vertex AI Workbench managed notebooks can import them.
To export custom routes, you
update
the peering connection
in your VPC. Exporting custom routes sends all
eligible
static and dynamic routes
that are
in your VPC network, such as routes to your on-premises network,
to service producers' networks (in this case, managed notebooks).
This establishes the necessary connections and lets
managed notebooks instances send traffic back
to your on-premises network.
To list the name of the peering connection to update,
use the following command.
If you have multiple peering connections, omit the
--format
flag.
gcloud
services
vpc-peerings
list
\
--network
=
NETWORK_NAME
\
--service
=
servicenetworking.googleapis.com
\
--project
=
PROJECT_ID
\
--format
"value(peering)"
To update the peering connection to export custom routes,
use the following command.
gcloud
compute
networks
peerings
update
PEERING_NAME
\
--network
=
NETWORK_NAME
\
--export-custom-routes
\
--project
=
PROJECT_ID
Replace
PEERING_NAME
with the name of your peering connection.
Check the state of your peering connections
To check whether your peering connections are active,
you can list them using the following command.
gcloud
compute
networks
peerings
list
--network
NETWORK_NAME
Verify that the state of the peering connection that
you just created is
ACTIVE
.
Learn more about
active
peering connections
.
What's next
Learn more about
VPC Network Peering
.
See
reference architectures and
best practices
for VPC design.
Send feedback
Except as otherwise noted, the content of this page is licensed under the
Creative Commons Attribution 4.0 License
, and code samples are licensed under the
Apache 2.0 License
. For details, see the
Google Developers Site Policies
. Java is a registered trademark of Oracle and/or its affiliates.
Last updated 2025-10-28 UTC.
Products and pricing
See all products
Google Cloud pricing
Google Cloud Marketplace
Contact sales
Support
Google Cloud Community
Support
Release Notes
System status
Resources
GitHub
Getting Started with Google Cloud
Code samples
Cloud Architecture Center
Training and Certification
Engage
Blog
Events
X (Twitter)
Google Cloud on YouTube
Google Cloud Tech on YouTube
About Google
Privacy
Site terms
Google Cloud terms
Manage cookies
Our third decade of climate action: join us
Sign up for the Google Cloud newsletter
Subscribe
English
Deutsch
Español – América Latina
Français
Português – Brasil
中文 – 简体
日本語
한국어